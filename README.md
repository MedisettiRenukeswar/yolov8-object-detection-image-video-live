# ğŸ§  YOLOv8 Object Detection â€” Images Â· Video Â· Webcam

This repo provides a clean, modular, and beginner-friendly YOLOv8 object detection pipeline using **Ultralytics YOLOv8** + **OpenCV**, with scripts for:

- Image inference  
- Video inference  
- Live webcam detection  
- MP4 recording  
- Easy annotation utilities  

Everything is structured exactly like a production-ready CV toolkit.

---

# ğŸ“¸ Preview (Output Examples)

### **Image Detection**
![Detected Image](outputs/detected.jpg)
![Detected Image](outputs/detected2.jpg)

### **Video Detection (Annotated MP4)**
![Detected Video](outputs/detected.mp4)
![Detected Video](outputs/detected2.mp4)

### **Webcam Detection (Live View + Recording Support)**
![Webcam Detection](outputs/webcam_record.mp4)

*(Replace these with your real outputs once generated.)*

---

# âš¡ Quickstart

## ** Install dependencies**
```bash
pip install -r requirements.txt
```
## ğŸ–¼ï¸ **Run Image Inference**
```bash
python scripts/detect_image.py samples/input.jpg outputs/detected_image.jpg
```
## ğŸ–¼ï¸ **Run Video Inference**
```bash
python scripts/detect_video.py samples/test.mp4 outputs/detected_video.mp4
```
## ğŸ–¼ï¸ **Run Webcam Detection (press q to quit)**
```bash
python scripts/detect_webcam.py
```
## ğŸ–¼ï¸ **Record webcam output to MP4**
```bash
python scripts/detect_webcam.py outputs/webcam_record.mp4
```

---


# ğŸ“ Project Structure
```text
yolov8-object-detection/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ detect_image.py          # Image inference
â”‚   â”œâ”€â”€ detect_video.py          # Video inference + MP4 writer
â”‚   â”œâ”€â”€ detect_webcam.py         # Live detection + optional MP4 recording
â”‚   â””â”€â”€ utils.py                 # Shared helpers (annotation, model loading)
â”‚
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ input.jpg                # Example image
â”‚   â””â”€â”€ input.mp4                 # Example video
â”‚
â”œâ”€â”€ outputs/                     # All generated detections saved here
â”‚   â”œâ”€â”€ detected.jpg                # Example image
â”‚   â””â”€â”€ detected.mp4                 # Example video
â”‚
â”œâ”€â”€ models/ (optional)           # Place custom YOLO weights (yolov8s.pt, custom.pt)
â”‚
â””â”€â”€ README.md
```

---

# ğŸ§© How Detection Works

- Load YOLOv8 model (Ultralytics API)
- Run inference on each frame (image / video / webcam)
- Extract detections:
    - Bounding boxes
    - Class IDs
    - Confidence scores
- Annotate frame with OpenCV rectangles + labels
- Save output (image or MP4 video)
    - Webcam mode can record automatically

---

## âš™ï¸ Switching YOLO Models (Accuracy vs Speed)

| Model        | Speed        | Accuracy | Best For              |
|--------------|--------------|----------|------------------------|
| **yolov8n.pt** | âš¡ Very Fast  | Medium   | Real-time webcam       |
| **yolov8s.pt** | Fast         | Better   | General use            |
| **yolov8m/l.pt** | Medium       | High     | Projects / demos       |
| **yolov8x.pt** | Slow         | ğŸ”¥ Highest | Research / heavy tasks |

---

## ğŸš€ Features at a Glance (Why This Repo Is Useful)

```text
âœ… Works on images, videos, webcam
âœ… MP4 recording built-in
âœ… Switch models instantly (nano â†’ xlarge)
âœ… Pure Python + OpenCV + Ultralytics
âœ… Zero boilerplate â€” clean reusable scripts
âœ… Auto-create folders & safe file handling
âœ… Beginner-friendly structure but production-ready
```

## ğŸ› ï¸ Under the Hood â€” Pipeline Breakdown

Every script in this repo follows the same high-level pipeline:
```bash
Frame â†’ YOLO Inference â†’ Parse Boxes â†’ Annotate â†’ Save/Display
```
# ğŸ” Step-by-Step YOLOv8 Detection Pipeline

This section explains exactly how every script in this repo works internally â€” from reading a frame to generating fully annotated detections.

---

## ğŸ§µ **Full Pipeline (Frame â†’ YOLO â†’ Annotation â†’ Output)**

1ï¸âƒ£ **Read a frame**
- From image / video / webcam

2ï¸âƒ£ **Convert color space**
- OpenCV uses **BGR**
- YOLOv8 internally converts to **RGB**

3ï¸âƒ£ **Run YOLOv8 inference**
```python
results = model.predict(source=frame, conf=0.25, imgsz=640)
```

4ï¸âƒ£ **Extract Detections**
- **boxes** â†’ `[x1, y1, x2, y2]`
- **scores** â†’ confidence values
- **class_ids** â†’ category indices (0â€“79 for COCO dataset)

5ï¸âƒ£ **Annotate Frame**
- Draw bounding boxes on detected objects  
- Render label + confidence score  
- Apply color overlays for visibility  

6ï¸âƒ£ **Output**
- **Images** â†’ save annotated `.jpg`  
- **Videos** â†’ write annotated `.mp4`  
- **Webcam** â†’ display live stream (+ optional MP4 recording)

This modular design keeps the YOLOv8 pipeline clean, reusable, and production-ready.

---

### ğŸ§¬ What YOLOv8 Actually Does (Under the Hood)

YOLOv8 is a **one-stage detector**, engineered for high speed and strong accuracy.

#### ğŸ§± Backbone
- Deep **CSP/Conv** layers  
- Extracts multi-scale hierarchical visual features  
- Learns textures, edges, shapes, objects

#### ğŸš§ Neck
- **PAN / FPN** feature fusion  
- Merges **low-level detail** with **high-level semantics**  
- Crucial for detecting **both tiny and large** objects

#### ğŸ¯ Detection Head (Decoupled)
- **Objectness score** â†’ "Is there an object here?"  
- **Class probabilities** â†’ "What object is it?"  
- **Bounding box regression** â†’ precise box coordinates  

#### âš¡ Why YOLOv8 Is Extremely Fast
- **Single forward pass** (one-shot detection)  
- **No region proposals** (unlike Faster R-CNN)  
- Highly optimized GPU kernels  
- **Anchor-free** detection â†’ simpler + faster  
- Layer fusion similar to TensorRT acceleration  

YOLOv8 balances **speed, accuracy, and simplicity**, making it ideal for real-time applications.

---

### ğŸ›ï¸ Parameter Tuning (Speed â†” Accuracy)

**Increase accuracy**
```python
model = load_model("yolov8l.pt")
results = model.predict(frame, conf=0.20)
```
**Increase speed**
```python
model = load_model("yolov8n.pt")
results = model.predict(frame, imgsz=480)
```

**Reduce false positives**
```python
results = model.predict(frame, conf=0.35)
```

**Detect smaller objects better**
```python
results = model.predict(frame, conf=0.20, imgsz=960)
```

---

## ğŸ“Š Supported Classes (COCO-80)

YOLOv8 models (n/s/m/l/x) detect 80 common classes, including:

- Person
- Car, truck, bus, motorcycle
- Dog, cat, horse
- Bottle, cup, bowl
- Laptop, keyboard, phone
- Chair, couch, bed
- Traffic light, stop sign
- And many moreâ€¦

Print the full class list:
```python
print(model.model.names)
```

---

### ğŸ§© Extensions You Can Build on Top of This Repo

Take this project from simple **object detection** to a full **computer vision system** by adding any of these modules:

---

#### ğŸ”¹ A. DeepSORT Object Tracking  
Assign unique IDs to each object and track them across frames.  
Useful for: pedestrians, vehicles, sports analytics, robotics.

---

#### ğŸ”¹ B. Zone Monitoring / Intrusion Detection  
Draw polygonal zones and trigger alerts when objects enter them.  
Perfect for:  
- Factory floor safety  
- Smart CCTV  
- Restricted access areas  

---

#### ğŸ”¹ C. People Counting  
Count how many people cross a virtual line (â€œline crossing analyticsâ€).  
Used in: malls, public transport, event monitoring.

---

#### ğŸ”¹ D. Face Blurring / Privacy Mode  
Automatically detect & blur human faces from YOLO + OpenCV.  
Important for privacy compliance (GDPR-like requirements).

---

#### ğŸ”¹ E. Multi-Class Color Coding  
Use different bounding box colors per object class for better visualization.  
Example:  
- Person â†’ green  
- Vehicle â†’ blue  
- Animal â†’ orange  

---

#### ğŸ”¹ F. Real-Time Speed Estimation  
Track object movement distance between frames to estimate speed.  
Useful for:  
- Traffic analytics  
- Sports performance tracking  
- Robotics navigation  

---

### ğŸ§ª Benchmark Performance (Real Numbers)

Use this quick snippet to measure inference FPS:

```python
import time
t0 = time.time()
results = model.predict(frame)
fps = 1 / (time.time() - t0)
print(f"FPS: {fps:.2f}")
```

---

## ğŸš€ Why This Repo Is Valuable (For Your Career)
```text
This repo demonstrates:

âœ” Ability to structure ML/CV code professionally
âœ” Understanding of YOLO pipelines
âœ” Ability to process image, video, and real-time streams
âœ” Practical debugging, annotation, and visualization
âœ” Production-ready usage of OpenCV + Ultralytics
```

---
